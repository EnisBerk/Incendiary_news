{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk \n",
    "import string\n",
    "import copy\n",
    "import random\n",
    "from os import listdir\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier,LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from pos_tagger import tag\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "# import zipfile\n",
    "# zip_ref = zipfile.ZipFile(\"TurkishStemmer.zip\", 'r')\n",
    "# zip_ref.extractall(\"./\")\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts = pickle.load( open( \"./data/clean_data.p\", \"rb\" ) )\n",
    "\n",
    "article_text_dict_positive=all_dicts[\"article_text_dict_positive\"]\n",
    "iter1_BBC_text_dict_neg=all_dicts[\"iter1_BBC_text_dict_neg\"]\n",
    "iter2_BBC_text_dict_neg=all_dicts[\"iter2_BBC_text_dict_neg\"]\n",
    "iter1_CNN_neg_text=all_dicts[\"iter1_CNN_neg_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "1031\n",
      "948\n",
      "1036\n"
     ]
    }
   ],
   "source": [
    "print(len(iter1_BBC_text_dict_neg))\n",
    "print(len(iter2_BBC_text_dict_neg))\n",
    "print(len(iter1_CNN_neg_text))\n",
    "print(len(article_text_dict_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowercase=' abcdefghijklmnoprstuvyzğöıüşç'\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "# There are different tokenization functions\n",
    "\n",
    "# first one is tokenizes with nltk, lowers text \n",
    "# and applies stemming to each word\n",
    "def tokenize_stem(text):\n",
    "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    and stems text. Returns a list of them\"\"\"\n",
    "    text=nltk.word_tokenize(text.lower().strip())\n",
    "    tokens = [stemmer.stem(t) for t in text]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# lowers text\n",
    "# generates part of speech tags  \n",
    "# returns \"word+tag\" \n",
    "# tokenization made with tagging library\n",
    "def pos_tokenize(text):\n",
    "    text=text.lower().strip()\n",
    "    tokens=[]\n",
    "    tags=tag(text)\n",
    "    for a_tag in tags:\n",
    "        tokens.append(a_tag[0]+\"+\"+a_tag[1])\n",
    "    return tokens\n",
    "\n",
    "# lowers text\n",
    "# splits text to it's characters\n",
    "def char_tokenize(text):\n",
    "    text = text.lower().strip()\n",
    "    tokens = [t for t in text]\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features={\"Pos_tags\":pos_tokenize,\"characters\":char_tokenize,\"tokenize\":nltk.word_tokenize,\"tokenize_stem\":tokenize_stem}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment_w_features(X_train,X_test,y_train,y_test,feature,n_range,theclassifiers,vectorizer=None):\n",
    "    if vectorizer==None:\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            tokenizer= features[feature],\n",
    "#             cleaning itself\n",
    "#             preprocessor=word_process_clean,\n",
    "            ngram_range=n_range,\n",
    "            use_idf=True,\n",
    "            min_df=0.003,\n",
    "            norm=None, )\n",
    "        \n",
    "    \n",
    "    X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "    X_test=vectorizer.transform(X_test).toarray()\n",
    "\n",
    "    if type(theclassifiers)!=list:\n",
    "        theclassifiers=[theclassifiers]\n",
    "    for theclassifier in theclassifiers:\n",
    "#       initialise classifier\n",
    "        if theclassifier==LinearSVC:\n",
    "            clf= theclassifier(max_iter=3000)\n",
    "        else:\n",
    "            clf= theclassifier()\n",
    "#     create model with tranining data\n",
    "        model = clf.fit(X_train, y_train)\n",
    "#     predict test set\n",
    "        y_preds = model.predict(X_test)\n",
    "#     create the report\n",
    "        report = classification_report( y_test, y_preds )\n",
    "    \n",
    "#     find name of the classifier for printing\n",
    "        match=re.search(r\"\\.([A-z]*)'>\",str(theclassifier))\n",
    "        match=match.group(1)\n",
    "\n",
    "        result_text=\"\\033[1m Performance report of \\033[0m \\033[92m\" + feature +\"\\033[0m \"\n",
    "        count=0\n",
    "        for i in range(n_range[0],n_range[1]+1):\n",
    "            if count!=0:\n",
    "                result_text+=\" and \"\n",
    "            result_text=result_text+\"\\033[91m\"+str(i)+\"-gram\\033[0m\"\n",
    "            count+=1\n",
    "        result_text+= \" with \\033[94m\"+match+\"\\033[0m\"\n",
    "    #     print(\"Performance report of {} {}-gram\".format(feature,n_range[1]))\n",
    "        print (result_text)\n",
    "#         prnt_scores(report)\n",
    "        print(report)\n",
    "        print(accuracy_score( y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos 828 test_pos 208\n",
      "train_neg 824 test_neg 207\n",
      "X_train 1652 Y_train 1652 X_test 415 Y_test 415\n"
     ]
    }
   ],
   "source": [
    "pos_examp=[]\n",
    "neg_examp_train=[]\n",
    "neg_examp_test=[]\n",
    "\n",
    "for key,artc in article_text_dict_positive.items():\n",
    "    pos_examp.append((artc,1))\n",
    "\n",
    "for artc in iter2_BBC_text_dict_neg.values():\n",
    "    neg_examp_train.append((artc,0))\n",
    "\n",
    "for artc in iter1_CNN_neg_text.values():\n",
    "    neg_examp_test.append((artc,0))\n",
    "\n",
    "\n",
    "# combine positive and negative samples then shuffle\n",
    "# XY=pos_examp+neg_examp_train\n",
    "random.seed(a=2)\n",
    "random.shuffle(pos_examp)\n",
    "random.shuffle(neg_examp_train)\n",
    "random.shuffle(neg_examp_test)\n",
    "\n",
    "percentage=0.8\n",
    "cut_point=int(len(pos_examp)*percentage)\n",
    "train_pos=pos_examp[:cut_point]\n",
    "test_pos=pos_examp[cut_point:]\n",
    "\n",
    "cut_point=int(len(neg_examp_train)*percentage)\n",
    "train_neg=neg_examp_train[:cut_point]\n",
    "cut_point=int(len(neg_examp_train)*percentage)\n",
    "test_neg=neg_examp_train[cut_point:]\n",
    "\n",
    "print(\"train_pos\",len(train_pos),\"test_pos\",len(test_pos))\n",
    "print(\"train_neg\",len(train_neg),\"test_neg\",len(test_neg))\n",
    "\n",
    "XY_train=train_pos+train_neg\n",
    "random.shuffle(XY_train)\n",
    "X_train=[k[0] for k in XY_train]\n",
    "Y_train=[k[1] for k in XY_train]\n",
    "\n",
    "XY_test=test_pos+test_neg\n",
    "random.shuffle(XY_test)\n",
    "X_test=[k[0] for k in XY_test]\n",
    "Y_test=[k[1] for k in XY_test]\n",
    "\n",
    "print(\"X_train\",len(X_train),\"Y_train\",len(Y_train),\"X_test\",len(X_test),\"Y_test\",len(Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers_list=[LinearSVC,MultinomialNB,RandomForestClassifier,\n",
    "                  AdaBoostClassifier]\n",
    "tryfeatures={\"tokenize\":nltk.word_tokenize,\"tokenize_stem\":tokenize_stem,\"Pos_tags\":pos_tokenize,\"characters\":char_tokenize}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1031"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_examp_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       207\n",
      "           1       0.98      0.96      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9686746987951808\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       207\n",
      "           1       0.98      0.97      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9734939759036144\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       207\n",
      "           1       0.98      0.97      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9734939759036144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       207\n",
      "           1       0.85      0.91      0.88       208\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       415\n",
      "   macro avg       0.88      0.87      0.87       415\n",
      "weighted avg       0.88      0.87      0.87       415\n",
      "\n",
      "0.8746987951807229\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.87       207\n",
      "           1       0.85      0.92      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8795180722891566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.58      0.70       207\n",
      "           1       0.69      0.93      0.79       208\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       415\n",
      "   macro avg       0.79      0.76      0.75       415\n",
      "weighted avg       0.79      0.76      0.75       415\n",
      "\n",
      "0.7566265060240964\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       207\n",
      "           1       0.96      0.98      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9686746987951808\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       207\n",
      "           1       0.96      0.98      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9662650602409638\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       207\n",
      "           1       0.96      0.98      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9662650602409638\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       207\n",
      "           1       0.88      0.92      0.90       208\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       415\n",
      "   macro avg       0.90      0.90      0.90       415\n",
      "weighted avg       0.90      0.90      0.90       415\n",
      "\n",
      "0.8987951807228916\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       207\n",
      "           1       0.88      0.92      0.90       208\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       415\n",
      "   macro avg       0.90      0.90      0.90       415\n",
      "weighted avg       0.90      0.90      0.90       415\n",
      "\n",
      "0.8963855421686747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.72       207\n",
      "           1       0.71      0.89      0.79       208\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       415\n",
      "   macro avg       0.78      0.76      0.76       415\n",
      "weighted avg       0.78      0.76      0.76       415\n",
      "\n",
      "0.7614457831325301\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       207\n",
      "           1       0.98      0.96      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9686746987951808\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       207\n",
      "           1       0.98      0.97      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9734939759036144\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       207\n",
      "           1       0.98      0.97      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9734939759036144\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       207\n",
      "           1       0.85      0.91      0.88       208\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       415\n",
      "   macro avg       0.88      0.87      0.87       415\n",
      "weighted avg       0.88      0.87      0.87       415\n",
      "\n",
      "0.8746987951807229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.87       207\n",
      "           1       0.85      0.92      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8795180722891566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.58      0.70       207\n",
      "           1       0.69      0.93      0.79       208\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       415\n",
      "   macro avg       0.79      0.76      0.75       415\n",
      "weighted avg       0.79      0.76      0.75       415\n",
      "\n",
      "0.7566265060240964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       207\n",
      "           1       0.88      0.88      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8819277108433735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       207\n",
      "           1       0.91      0.96      0.93       208\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       415\n",
      "   macro avg       0.93      0.93      0.93       415\n",
      "weighted avg       0.93      0.93      0.93       415\n",
      "\n",
      "0.9325301204819277\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       207\n",
      "           1       0.95      0.98      0.96       208\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       415\n",
      "   macro avg       0.96      0.96      0.96       415\n",
      "weighted avg       0.96      0.96      0.96       415\n",
      "\n",
      "0.9614457831325302\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       207\n",
      "           1       0.93      0.95      0.94       208\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       415\n",
      "   macro avg       0.94      0.94      0.94       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "0.9373493975903614\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       207\n",
      "           1       0.95      0.97      0.96       208\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       415\n",
      "   macro avg       0.96      0.96      0.96       415\n",
      "weighted avg       0.96      0.96      0.96       415\n",
      "\n",
      "0.9614457831325302\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mLinearSVC\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       207\n",
      "           1       0.97      0.98      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9734939759036144\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       207\n",
      "           1       0.98      0.95      0.96       208\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       415\n",
      "   macro avg       0.96      0.96      0.96       415\n",
      "weighted avg       0.96      0.96      0.96       415\n",
      "\n",
      "0.963855421686747\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       207\n",
      "           1       0.98      0.95      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9662650602409638\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       207\n",
      "           1       0.99      0.96      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9734939759036144\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       207\n",
      "           1       0.97      0.90      0.94       208\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       415\n",
      "   macro avg       0.94      0.94      0.94       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "0.9397590361445783\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       207\n",
      "           1       0.97      0.90      0.94       208\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       415\n",
      "   macro avg       0.94      0.94      0.94       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "0.9397590361445783\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77       207\n",
      "           1       0.74      0.90      0.81       208\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       415\n",
      "   macro avg       0.81      0.79      0.79       415\n",
      "weighted avg       0.81      0.79      0.79       415\n",
      "\n",
      "0.7927710843373494\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       207\n",
      "           1       0.95      0.96      0.96       208\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       415\n",
      "   macro avg       0.96      0.96      0.96       415\n",
      "weighted avg       0.96      0.96      0.96       415\n",
      "\n",
      "0.9566265060240964\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       207\n",
      "           1       0.95      0.96      0.95       208\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       415\n",
      "   macro avg       0.95      0.95      0.95       415\n",
      "weighted avg       0.95      0.95      0.95       415\n",
      "\n",
      "0.9542168674698795\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       207\n",
      "           1       0.94      0.96      0.95       208\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       415\n",
      "   macro avg       0.95      0.95      0.95       415\n",
      "weighted avg       0.95      0.95      0.95       415\n",
      "\n",
      "0.9493975903614458\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       207\n",
      "           1       0.95      0.93      0.94       208\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       415\n",
      "   macro avg       0.94      0.94      0.94       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "0.9373493975903614\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       207\n",
      "           1       0.99      0.96      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9734939759036144\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       207\n",
      "           1       0.97      0.90      0.94       208\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       415\n",
      "   macro avg       0.94      0.94      0.94       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "0.9397590361445783\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       207\n",
      "           1       0.97      0.90      0.94       208\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       415\n",
      "   macro avg       0.94      0.94      0.94       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "0.9397590361445783\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77       207\n",
      "           1       0.74      0.90      0.81       208\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       415\n",
      "   macro avg       0.81      0.79      0.79       415\n",
      "weighted avg       0.81      0.79      0.79       415\n",
      "\n",
      "0.7927710843373494\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       207\n",
      "           1       0.87      0.75      0.80       208\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       415\n",
      "   macro avg       0.82      0.81      0.81       415\n",
      "weighted avg       0.82      0.81      0.81       415\n",
      "\n",
      "0.8144578313253013\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       207\n",
      "           1       0.97      0.85      0.91       208\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       415\n",
      "   macro avg       0.92      0.91      0.91       415\n",
      "weighted avg       0.92      0.91      0.91       415\n",
      "\n",
      "0.9132530120481928\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       207\n",
      "           1       0.98      0.92      0.95       208\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       415\n",
      "   macro avg       0.96      0.95      0.95       415\n",
      "weighted avg       0.96      0.95      0.95       415\n",
      "\n",
      "0.9542168674698795\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       207\n",
      "           1       0.97      0.86      0.91       208\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       415\n",
      "   macro avg       0.92      0.92      0.92       415\n",
      "weighted avg       0.92      0.92      0.92       415\n",
      "\n",
      "0.9156626506024096\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       207\n",
      "           1       0.98      0.92      0.95       208\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       415\n",
      "   macro avg       0.96      0.95      0.95       415\n",
      "weighted avg       0.96      0.95      0.95       415\n",
      "\n",
      "0.9542168674698795\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mMultinomialNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       207\n",
      "           1       0.98      0.94      0.96       208\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       415\n",
      "   macro avg       0.96      0.96      0.96       415\n",
      "weighted avg       0.96      0.96      0.96       415\n",
      "\n",
      "0.9614457831325302\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       207\n",
      "           1       0.95      0.84      0.89       208\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       415\n",
      "   macro avg       0.90      0.89      0.89       415\n",
      "weighted avg       0.90      0.89      0.89       415\n",
      "\n",
      "0.8939759036144578\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       207\n",
      "           1       0.96      0.87      0.91       208\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       415\n",
      "   macro avg       0.92      0.91      0.91       415\n",
      "weighted avg       0.92      0.91      0.91       415\n",
      "\n",
      "0.9132530120481928\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       207\n",
      "           1       0.92      0.83      0.87       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8771084337349397\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       207\n",
      "           1       0.83      0.77      0.80       208\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       415\n",
      "   macro avg       0.81      0.81      0.81       415\n",
      "weighted avg       0.81      0.81      0.81       415\n",
      "\n",
      "0.8096385542168675\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       207\n",
      "           1       0.82      0.82      0.82       208\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       415\n",
      "   macro avg       0.82      0.82      0.82       415\n",
      "weighted avg       0.82      0.82      0.82       415\n",
      "\n",
      "0.8216867469879519\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.65      0.75       207\n",
      "           1       0.73      0.92      0.81       208\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       415\n",
      "   macro avg       0.81      0.79      0.78       415\n",
      "weighted avg       0.81      0.79      0.78       415\n",
      "\n",
      "0.7879518072289157\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91       207\n",
      "           1       0.92      0.88      0.90       208\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       415\n",
      "   macro avg       0.90      0.90      0.90       415\n",
      "weighted avg       0.90      0.90      0.90       415\n",
      "\n",
      "0.9036144578313253\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       207\n",
      "           1       0.93      0.85      0.89       208\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       415\n",
      "   macro avg       0.89      0.89      0.89       415\n",
      "weighted avg       0.89      0.89      0.89       415\n",
      "\n",
      "0.891566265060241\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       207\n",
      "           1       0.94      0.83      0.88       208\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       415\n",
      "   macro avg       0.89      0.89      0.89       415\n",
      "weighted avg       0.89      0.89      0.89       415\n",
      "\n",
      "0.8867469879518072\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       207\n",
      "           1       0.85      0.79      0.82       208\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       415\n",
      "   macro avg       0.83      0.82      0.82       415\n",
      "weighted avg       0.83      0.82      0.82       415\n",
      "\n",
      "0.8240963855421687\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       207\n",
      "           1       0.84      0.84      0.84       208\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       415\n",
      "   macro avg       0.84      0.84      0.84       415\n",
      "weighted avg       0.84      0.84      0.84       415\n",
      "\n",
      "0.8385542168674699\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76       207\n",
      "           1       0.73      0.92      0.82       208\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       415\n",
      "   macro avg       0.81      0.79      0.79       415\n",
      "weighted avg       0.81      0.79      0.79       415\n",
      "\n",
      "0.7927710843373494\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       207\n",
      "           1       0.91      0.79      0.84       208\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       415\n",
      "   macro avg       0.86      0.85      0.85       415\n",
      "weighted avg       0.86      0.85      0.85       415\n",
      "\n",
      "0.8530120481927711\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       207\n",
      "           1       0.93      0.83      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.89      0.88      0.88       415\n",
      "weighted avg       0.89      0.88      0.88       415\n",
      "\n",
      "0.8843373493975903\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       207\n",
      "           1       0.96      0.84      0.90       208\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       415\n",
      "   macro avg       0.91      0.90      0.90       415\n",
      "weighted avg       0.91      0.90      0.90       415\n",
      "\n",
      "0.9012048192771084\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       207\n",
      "           1       0.86      0.81      0.83       208\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       415\n",
      "   macro avg       0.84      0.84      0.84       415\n",
      "weighted avg       0.84      0.84      0.84       415\n",
      "\n",
      "0.8361445783132531\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       207\n",
      "           1       0.83      0.80      0.81       208\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       415\n",
      "   macro avg       0.82      0.82      0.82       415\n",
      "weighted avg       0.82      0.82      0.82       415\n",
      "\n",
      "0.8168674698795181\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.65      0.75       207\n",
      "           1       0.73      0.93      0.81       208\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       415\n",
      "   macro avg       0.81      0.79      0.78       415\n",
      "weighted avg       0.81      0.79      0.78       415\n",
      "\n",
      "0.7879518072289157\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       207\n",
      "           1       0.83      0.68      0.75       208\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       415\n",
      "   macro avg       0.78      0.77      0.77       415\n",
      "weighted avg       0.78      0.77      0.77       415\n",
      "\n",
      "0.7686746987951807\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       207\n",
      "           1       0.92      0.83      0.87       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8771084337349397\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       207\n",
      "           1       0.90      0.82      0.86       208\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       415\n",
      "   macro avg       0.87      0.86      0.86       415\n",
      "weighted avg       0.87      0.86      0.86       415\n",
      "\n",
      "0.8626506024096385\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       207\n",
      "           1       0.95      0.86      0.90       208\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       415\n",
      "   macro avg       0.91      0.91      0.91       415\n",
      "weighted avg       0.91      0.91      0.91       415\n",
      "\n",
      "0.9060240963855422\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       207\n",
      "           1       0.94      0.86      0.90       208\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       415\n",
      "   macro avg       0.90      0.90      0.90       415\n",
      "weighted avg       0.90      0.90      0.90       415\n",
      "\n",
      "0.9012048192771084\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mRandomForestClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       207\n",
      "           1       0.95      0.82      0.88       208\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       415\n",
      "   macro avg       0.90      0.89      0.89       415\n",
      "weighted avg       0.90      0.89      0.89       415\n",
      "\n",
      "0.8891566265060241\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       207\n",
      "           1       0.90      0.86      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8819277108433735\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       207\n",
      "           1       0.90      0.86      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8819277108433735\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       207\n",
      "           1       0.90      0.86      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8819277108433735\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.79       207\n",
      "           1       0.76      0.88      0.82       208\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       415\n",
      "   macro avg       0.81      0.80      0.80       415\n",
      "weighted avg       0.81      0.80      0.80       415\n",
      "\n",
      "0.8024096385542169\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.79       207\n",
      "           1       0.76      0.88      0.82       208\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       415\n",
      "   macro avg       0.81      0.80      0.80       415\n",
      "weighted avg       0.81      0.80      0.80       415\n",
      "\n",
      "0.8024096385542169\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.40      0.57       207\n",
      "           1       0.62      0.99      0.77       208\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       415\n",
      "   macro avg       0.80      0.70      0.67       415\n",
      "weighted avg       0.80      0.70      0.67       415\n",
      "\n",
      "0.6963855421686747\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       207\n",
      "           1       0.89      0.88      0.89       208\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       415\n",
      "   macro avg       0.89      0.89      0.89       415\n",
      "weighted avg       0.89      0.89      0.89       415\n",
      "\n",
      "0.8867469879518072\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       207\n",
      "           1       0.92      0.87      0.90       208\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       415\n",
      "   macro avg       0.90      0.90      0.90       415\n",
      "weighted avg       0.90      0.90      0.90       415\n",
      "\n",
      "0.8987951807228916\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       207\n",
      "           1       0.92      0.87      0.90       208\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       415\n",
      "   macro avg       0.90      0.90      0.90       415\n",
      "weighted avg       0.90      0.90      0.90       415\n",
      "\n",
      "0.8987951807228916\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.79       207\n",
      "           1       0.77      0.90      0.83       208\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       415\n",
      "   macro avg       0.82      0.81      0.81       415\n",
      "weighted avg       0.82      0.81      0.81       415\n",
      "\n",
      "0.8120481927710843\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.79       207\n",
      "           1       0.77      0.90      0.83       208\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       415\n",
      "   macro avg       0.82      0.81      0.81       415\n",
      "weighted avg       0.82      0.81      0.81       415\n",
      "\n",
      "0.8120481927710843\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.49      0.65       207\n",
      "           1       0.66      0.99      0.79       208\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       415\n",
      "   macro avg       0.82      0.74      0.72       415\n",
      "weighted avg       0.82      0.74      0.72       415\n",
      "\n",
      "0.7397590361445783\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       207\n",
      "           1       0.90      0.86      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8819277108433735\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       207\n",
      "           1       0.90      0.86      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8819277108433735\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       207\n",
      "           1       0.90      0.86      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8819277108433735\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.79       207\n",
      "           1       0.76      0.88      0.82       208\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       415\n",
      "   macro avg       0.81      0.80      0.80       415\n",
      "weighted avg       0.81      0.80      0.80       415\n",
      "\n",
      "0.8024096385542169\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.79       207\n",
      "           1       0.76      0.88      0.82       208\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       415\n",
      "   macro avg       0.81      0.80      0.80       415\n",
      "weighted avg       0.81      0.80      0.80       415\n",
      "\n",
      "0.8024096385542169\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.40      0.57       207\n",
      "           1       0.62      0.99      0.77       208\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       415\n",
      "   macro avg       0.80      0.70      0.67       415\n",
      "weighted avg       0.80      0.70      0.67       415\n",
      "\n",
      "0.6963855421686747\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79       207\n",
      "           1       0.79      0.77      0.78       208\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       415\n",
      "   macro avg       0.78      0.78      0.78       415\n",
      "weighted avg       0.78      0.78      0.78       415\n",
      "\n",
      "0.7831325301204819\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       207\n",
      "           1       0.91      0.93      0.92       208\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       415\n",
      "   macro avg       0.92      0.92      0.92       415\n",
      "weighted avg       0.92      0.92      0.92       415\n",
      "\n",
      "0.9204819277108434\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m and \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       207\n",
      "           1       0.92      0.94      0.93       208\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       415\n",
      "   macro avg       0.93      0.93      0.93       415\n",
      "weighted avg       0.93      0.93      0.93       415\n",
      "\n",
      "0.9301204819277108\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       207\n",
      "           1       0.93      0.93      0.93       208\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       415\n",
      "   macro avg       0.93      0.93      0.93       415\n",
      "weighted avg       0.93      0.93      0.93       415\n",
      "\n",
      "0.927710843373494\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m and \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       207\n",
      "           1       0.92      0.94      0.93       208\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       415\n",
      "   macro avg       0.93      0.93      0.93       415\n",
      "weighted avg       0.93      0.93      0.93       415\n",
      "\n",
      "0.9301204819277108\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mAdaBoostClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       207\n",
      "           1       0.93      0.96      0.94       208\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       415\n",
      "   macro avg       0.94      0.94      0.94       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "0.9421686746987952\n"
     ]
    }
   ],
   "source": [
    "for clasifier in classifiers_list:\n",
    "    for feature in tryfeatures:\n",
    "        for i in range(1,4):\n",
    "            for k in range(i,4):\n",
    "                run_experiment_w_features(X_train[:],X_test[:],Y_train[:],Y_test[:],feature,(i,k),clasifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82       207\n",
      "           1       0.82      0.83      0.83       208\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       415\n",
      "   macro avg       0.82      0.82      0.82       415\n",
      "weighted avg       0.82      0.82      0.82       415\n",
      "\n",
      "0.8240963855421687\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       207\n",
      "           1       0.80      0.75      0.78       208\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       415\n",
      "   macro avg       0.78      0.78      0.78       415\n",
      "weighted avg       0.78      0.78      0.78       415\n",
      "\n",
      "0.7831325301204819\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73       207\n",
      "           1       0.71      0.90      0.80       208\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       415\n",
      "   macro avg       0.79      0.77      0.76       415\n",
      "weighted avg       0.79      0.77      0.76       415\n",
      "\n",
      "0.7686746987951807\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       207\n",
      "           1       0.80      0.81      0.80       208\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       415\n",
      "   macro avg       0.80      0.80      0.80       415\n",
      "weighted avg       0.80      0.80      0.80       415\n",
      "\n",
      "0.8024096385542169\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78       207\n",
      "           1       0.78      0.79      0.79       208\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       415\n",
      "   macro avg       0.79      0.79      0.79       415\n",
      "weighted avg       0.79      0.79      0.79       415\n",
      "\n",
      "0.7855421686746988\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73       207\n",
      "           1       0.71      0.89      0.79       208\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       415\n",
      "   macro avg       0.78      0.76      0.76       415\n",
      "weighted avg       0.78      0.76      0.76       415\n",
      "\n",
      "0.763855421686747\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       207\n",
      "           1       0.84      0.84      0.84       208\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       415\n",
      "   macro avg       0.84      0.84      0.84       415\n",
      "weighted avg       0.84      0.84      0.84       415\n",
      "\n",
      "0.8385542168674699\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       207\n",
      "           1       0.81      0.75      0.78       208\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       415\n",
      "   macro avg       0.79      0.79      0.79       415\n",
      "weighted avg       0.79      0.79      0.79       415\n",
      "\n",
      "0.7879518072289157\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.62      0.72       207\n",
      "           1       0.71      0.90      0.79       208\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       415\n",
      "   macro avg       0.78      0.76      0.76       415\n",
      "weighted avg       0.78      0.76      0.76       415\n",
      "\n",
      "0.7614457831325301\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73       207\n",
      "           1       0.72      0.75      0.74       208\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       415\n",
      "   macro avg       0.73      0.73      0.73       415\n",
      "weighted avg       0.73      0.73      0.73       415\n",
      "\n",
      "0.7325301204819277\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       207\n",
      "           1       0.85      0.84      0.84       208\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       415\n",
      "   macro avg       0.85      0.85      0.85       415\n",
      "weighted avg       0.85      0.85      0.85       415\n",
      "\n",
      "0.8457831325301205\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mDecisionTreeClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       207\n",
      "           1       0.84      0.86      0.85       208\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       415\n",
      "   macro avg       0.85      0.85      0.85       415\n",
      "weighted avg       0.85      0.85      0.85       415\n",
      "\n",
      "0.8481927710843373\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.85       207\n",
      "           1       0.80      0.96      0.88       208\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       415\n",
      "   macro avg       0.88      0.86      0.86       415\n",
      "weighted avg       0.88      0.86      0.86       415\n",
      "\n",
      "0.8626506024096385\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       207\n",
      "           1       0.89      0.86      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8771084337349397\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.56      0.70       207\n",
      "           1       0.69      0.96      0.80       208\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       415\n",
      "   macro avg       0.81      0.76      0.75       415\n",
      "weighted avg       0.81      0.76      0.75       415\n",
      "\n",
      "0.7614457831325301\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85       207\n",
      "           1       0.81      0.96      0.88       208\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       415\n",
      "   macro avg       0.88      0.86      0.86       415\n",
      "weighted avg       0.88      0.87      0.86       415\n",
      "\n",
      "0.8650602409638555\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       207\n",
      "           1       0.91      0.90      0.91       208\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       415\n",
      "   macro avg       0.91      0.91      0.91       415\n",
      "weighted avg       0.91      0.91      0.91       415\n",
      "\n",
      "0.9060240963855422\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.68       207\n",
      "           1       0.68      0.95      0.79       208\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       415\n",
      "   macro avg       0.79      0.75      0.74       415\n",
      "weighted avg       0.79      0.75      0.74       415\n",
      "\n",
      "0.7469879518072289\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.85       207\n",
      "           1       0.80      0.96      0.88       208\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       415\n",
      "   macro avg       0.88      0.86      0.86       415\n",
      "weighted avg       0.88      0.86      0.86       415\n",
      "\n",
      "0.8626506024096385\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       207\n",
      "           1       0.89      0.86      0.88       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.88      0.88      0.88       415\n",
      "weighted avg       0.88      0.88      0.88       415\n",
      "\n",
      "0.8771084337349397\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.56      0.70       207\n",
      "           1       0.69      0.96      0.80       208\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       415\n",
      "   macro avg       0.81      0.76      0.75       415\n",
      "weighted avg       0.81      0.76      0.75       415\n",
      "\n",
      "0.7614457831325301\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.48      0.56       207\n",
      "           1       0.59      0.75      0.66       208\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       415\n",
      "   macro avg       0.63      0.62      0.61       415\n",
      "weighted avg       0.63      0.62      0.61       415\n",
      "\n",
      "0.6168674698795181\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       207\n",
      "           1       0.91      0.75      0.82       208\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       415\n",
      "   macro avg       0.85      0.84      0.83       415\n",
      "weighted avg       0.85      0.84      0.83       415\n",
      "\n",
      "0.8361445783132531\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mGaussianNB\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80       207\n",
      "           1       0.77      0.90      0.83       208\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       415\n",
      "   macro avg       0.83      0.82      0.82       415\n",
      "weighted avg       0.83      0.82      0.82       415\n",
      "\n",
      "0.8168674698795181\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       207\n",
      "           1       0.96      0.99      0.98       208\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       415\n",
      "   macro avg       0.98      0.98      0.98       415\n",
      "weighted avg       0.98      0.98      0.98       415\n",
      "\n",
      "0.9759036144578314\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       207\n",
      "           1       0.94      0.92      0.93       208\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       415\n",
      "   macro avg       0.93      0.93      0.93       415\n",
      "weighted avg       0.93      0.93      0.93       415\n",
      "\n",
      "0.9325301204819277\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.62      0.73       207\n",
      "           1       0.71      0.91      0.80       208\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       415\n",
      "   macro avg       0.79      0.77      0.76       415\n",
      "weighted avg       0.79      0.77      0.76       415\n",
      "\n",
      "0.7686746987951807\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       207\n",
      "           1       0.96      0.99      0.97       208\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       415\n",
      "   macro avg       0.97      0.97      0.97       415\n",
      "weighted avg       0.97      0.97      0.97       415\n",
      "\n",
      "0.9710843373493976\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       207\n",
      "           1       0.93      0.96      0.95       208\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       415\n",
      "   macro avg       0.95      0.94      0.94       415\n",
      "weighted avg       0.95      0.94      0.94       415\n",
      "\n",
      "0.944578313253012\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mtokenize_stem\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.70      0.77       207\n",
      "           1       0.74      0.88      0.81       208\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       415\n",
      "   macro avg       0.80      0.79      0.79       415\n",
      "weighted avg       0.80      0.79      0.79       415\n",
      "\n",
      "0.7903614457831325\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       207\n",
      "           1       0.98      0.98      0.98       208\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       415\n",
      "   macro avg       0.98      0.98      0.98       415\n",
      "weighted avg       0.98      0.98      0.98       415\n",
      "\n",
      "0.9783132530120482\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       207\n",
      "           1       0.94      0.93      0.93       208\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       415\n",
      "   macro avg       0.94      0.93      0.93       415\n",
      "weighted avg       0.94      0.93      0.93       415\n",
      "\n",
      "0.9349397590361446\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mPos_tags\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.65      0.75       207\n",
      "           1       0.72      0.91      0.81       208\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       415\n",
      "   macro avg       0.80      0.78      0.78       415\n",
      "weighted avg       0.80      0.78      0.78       415\n",
      "\n",
      "0.7807228915662651\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m1-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89       207\n",
      "           1       0.96      0.79      0.87       208\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       415\n",
      "   macro avg       0.89      0.88      0.88       415\n",
      "weighted avg       0.89      0.88      0.88       415\n",
      "\n",
      "0.8795180722891566\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m2-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       207\n",
      "           1       0.93      0.96      0.95       208\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       415\n",
      "   macro avg       0.94      0.94      0.94       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "0.944578313253012\n",
      "\u001b[1m Performance report of \u001b[0m \u001b[92mcharacters\u001b[0m \u001b[91m3-gram\u001b[0m with \u001b[94mMLPClassifier\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       207\n",
      "           1       0.98      0.97      0.98       208\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       415\n",
      "   macro avg       0.98      0.98      0.98       415\n",
      "weighted avg       0.98      0.98      0.98       415\n",
      "\n",
      "0.9759036144578314\n"
     ]
    }
   ],
   "source": [
    "slow_classifiers_list=[DecisionTreeClassifier,GaussianNB,MLPClassifier]\n",
    "for clasifier in slow_classifiers_list:\n",
    "    for feature in tryfeatures:\n",
    "        for i in range(1,4):\n",
    "            run_experiment_w_features(X_train[:],X_test[:],Y_train[:],Y_test[:],feature,(i,i),clasifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myfile=open(\"results/4-(BBC-CNN).txt\")\n",
    "lines=myfile.readlines()\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(*lines[9:18])\n",
    "print(*lines[18:27])\n",
    "print(lines[18].strip()[23:].split(\" \")[0])\n",
    "print(lines[9].strip()[23:].split(\" and \"))\n",
    "print(lines[9].strip()[23:].split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(lines),9):\n",
    "    one_line=lines[i:i+9]\n",
    "    first_line=one_line[0].strip()[23:]\n",
    "    ngram=[]\n",
    "    ngrams=first_line.split(\" and \")\n",
    "    if len(ngrams)==2:\n",
    "        clasifier=first_line.split(\"with\")[1].strip()\n",
    "        ngram.append(ngrams[0][-6:])\n",
    "        ngram.append(ngrams[1][:6])\n",
    "        first_line=first_line.split(\" \")\n",
    "\n",
    "    elif len(ngrams)==3:\n",
    "        clasifier=first_line.split(\"with\")[1].strip()\n",
    "        ngram.append(ngrams[0][-6:])\n",
    "        ngram.append(ngrams[1])\n",
    "        ngram.append(ngrams[2][:6])\n",
    "        first_line=first_line.split(\" \")\n",
    "    else:\n",
    "        first_line=first_line.split(\" \")\n",
    "        ngram.append(first_line[1])\n",
    "        clasifier=first_line[3]\n",
    "    \n",
    "    feature=first_line[0]\n",
    "    precision=one_line[6].split(\" \")[9]\n",
    "    recall=one_line[6].split(\" \")[15]\n",
    "    f1score=one_line[6].split(\" \")[21]\n",
    "    accuray=one_line[8].strip()\n",
    "    for i,k in enumerate(ngram):\n",
    "        ngram[i]=k.split(\"-\")[0]\n",
    "#     +(\"%.2f\" % round(float(accuray),2))\n",
    "    if feature==\"characters\" and (ngram[0]==\"2\" ):\n",
    "        print(\"\\hline\")\n",
    "        print(classifiers_names[clasifier]+\" & \"+\",\".join(ngram)+\"-gram\"+\" & \"+precision+\" & \"+recall+\" & \"+f1score+\" \\\\\\\\\")\n",
    "#         print(feature,ngram,clasifier,accuray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\\hline\n",
    "Linear SVM (SVC) & 1-gram & 0.95 & 0.95 & 0.95 & 0.97 & 0.96 & 0.96 &  \\\\\n",
    "\\hline\n",
    "Linear SVM (SVC) & 1,2-gram & 0.96 & 0.96 & 0.96 & 0.98 & 0.98 & 0.98 &  \\\\\n",
    "\\hline\n",
    "Linear SVM (SVC) & 1,2,3-gram & 0.97 & 0.97 & 0.97 & 0.98 & 0.98 & 0.98 &  \\\\\n",
    "\\hline\n",
    "Multinomial NB & 1-gram & 0.95 & 0.94 & 0.94 & 0.97 & 0.96 & 0.96 &  \\\\\n",
    "\\hline\n",
    "Multinomial NB & 1,2-gram & 0.96 & 0.96 & 0.96 & 0.98 & 0.97 & 0.97 &  \\\\\n",
    "\\hline\n",
    "Multinomial NB & 1,2,3-gram & 0.96 & 0.96 & 0.96 & 0.98 & 0.97 & 0.97 &  \\\\\n",
    "\\hline\n",
    "Random Forest & 1-gram & 0.90 & 0.89 & 0.89 & 0.93 & 0.92 & 0.92 &  \\\\\n",
    "\\hline\n",
    "Random Forest & 1,2-gram & 0.91 & 0.90 & 0.90 & 0.94 & 0.93 & 0.93 &  \\\\\n",
    "\\hline\n",
    "Random Forest & 1,2,3-gram & 0.90 & 0.89 & 0.89 & 0.92 & 0.90 & 0.90 &  \\\\\n",
    "\\hline\n",
    "AdaBoost & 1-gram &0.88 & 0.88 & 0.88 & 0.26 & 0.46 & 0.33 &  \\\\\n",
    "\\hline\n",
    "AdaBoost & 1,2-gram &0.88 & 0.88 & 0.88 & 0.26 & 0.46 & 0.33 &  \\\\\n",
    "\\hline\n",
    "AdaBoost & 1,2,3-gram &0.88 & 0.88 & 0.88 & 0.26 & 0.46 & 0.33 &  \\\\\n",
    "\\hline\n",
    "Decision Tree & 1-gram &0.80 & 0.79 & 0.79 & 0.92 & 0.91 & 0.91 &  \\\\\n",
    "\\hline\n",
    "Gaussian NB & 1-gram &0.89 & 0.88 & 0.88 &  0.98 & 0.97 & 0.97 &  \\\\\n",
    "\\hline\n",
    "Multi-layer Perc. (MLP) & 1-gram &0.97 & 0.97 & 0.97 & 0.27 & 0.51 & 0.35 &  \\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(range(0,10,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_line=BBC_BBC_lines[9:9+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_line[0].strip()[23:].split(\"and\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    if \"Forest\" in line:\n",
    "        print (line.split(\"and\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers_names={\"LinearSVC\":\"Linear SVM (SVC)\",\"MultinomialNB\":\"Multinomial NB\",\"RandomForestClassifier\":\"Random Forest\",\n",
    "                  \"AdaBoostClassifier\":\"AdaBoost\",\"DecisionTreeClassifier\":\"Decision Tree\",\"GaussianNB\":\"Gaussian NB\",\"MLPClassifier\":\"Multi-layer Perc. (MLP)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
